{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human|ActivityTracking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "e1OShl3z6Tqe",
        "colab_type": "code",
        "outputId": "80839951-f697-4e7b-8e05-4c400aca2536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vVoKZHAv61Re",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path='./drive/My Drive/HumanActivityRecognition.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnbE2al87Ss4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tw0lej-X7flA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eethCqzo7se8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fynF1Bdf7vhZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATADIR = './HAR/UCI_HAR_Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SS6C0Sor769l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTC63S1l8Bou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename =f'./HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBX2c8IM8EQR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = f'./HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WyMnvrF8I6N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQ9Hd2_X8NJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNj1Wdnl8o0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configuring a session\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDGrjvxC8r-i",
        "colab_type": "code",
        "outputId": "50ea80fc-c0bd-4f35-8c4c-3d75f560df7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Import Keras\n",
        "from keras import backend as K\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jv_0dn3A8wpi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uaKpRwtc8uOR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfKNiU_g8z9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKS6U530833k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BE733KAl86Lj",
        "colab_type": "code",
        "outputId": "e2e7ed74-5ee7-4333-d4dc-9166215bc7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = _count_classes(Y_train)\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWaLKg9ZCZH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Hyperparameter Tuning For a single layer LSTM</h1>"
      ]
    },
    {
      "metadata": {
        "id": "fwmw2lWsHpp1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGmaXhfF_ram",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(n_hidden,rate):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n_hidden,recurrent_dropout=0.3, input_shape=(timesteps, input_dim)))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Dense(n_classes, activation='sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZkX4sLrEyVS",
        "colab_type": "code",
        "outputId": "d27b43a5-e903-4402-f10e-93fa303c3dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0,epochs=30, batch_size=16)\n",
        "n_hidden = [32, 64, 100]\n",
        "rate = [0.2,0.3, 0.5,0.6]\n",
        "param_grid = dict(n_hidden=n_hidden, rate=rate)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train,Y_train,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vphIazWRNS0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "be82a0fe-b86c-48f5-add5-91d68cbef998"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.928596 using {'n_hidden': 32, 'rate': 0.2}\n",
            "0.928596 (0.038793) with: {'n_hidden': 32, 'rate': 0.2}\n",
            "0.913798 (0.045925) with: {'n_hidden': 32, 'rate': 0.3}\n",
            "0.9193798 (0.051924) with: {'n_hidden': 32, 'rate': 0.5}\n",
            "0.628672 (0.007679) with: {'n_hidden': 32, 'rate': 0.6}\n",
            "0.911186 (0.020551) with: {'n_hidden': 64, 'rate': 0.2}\n",
            "0.902121 (0.020551) with: {'n_hidden': 64, 'rate': 0.3}\n",
            "0.859989 (0.111285) with: {'n_hidden': 64, 'rate': 0.5}\n",
            "0.917851 (0.015910) with: {'n_hidden': 64, 'rate': 0.6}\n",
            "0.904249 (0.021139) with: {'n_hidden': 100, 'rate': 0.2}\n",
            "0.92783 (0.020052) with: {'n_hidden': 100, 'rate': 0.3}\n",
            "0.90783 (0.014025) with: {'n_hidden': 100, 'rate': 0.5}\n",
            "0.8903645 (0.048856) with: {'n_hidden': 100, 'rate': 0.6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MmyKi0LB_TOp",
        "colab_type": "code",
        "outputId": "4e6e036a-3dc7-4cd4-ba5e-086525a8281b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-DeQCzTs1HJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_IpgLE5_l8r",
        "colab_type": "code",
        "outputId": "2fd9d125-0b52-4fad-8c4a-6c7b224a1fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 156s 21ms/step - loss: 1.2974 - acc: 0.4382 - val_loss: 1.1482 - val_acc: 0.4751\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 1.0829 - acc: 0.5246 - val_loss: 1.1560 - val_acc: 0.5059\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.8029 - acc: 0.6338 - val_loss: 0.8779 - val_acc: 0.6162\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.7732 - acc: 0.6470 - val_loss: 1.1862 - val_acc: 0.5192\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.6773 - acc: 0.6929 - val_loss: 0.7165 - val_acc: 0.7201\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.5663 - acc: 0.7682 - val_loss: 0.6743 - val_acc: 0.7414\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.4746 - acc: 0.8275 - val_loss: 0.5975 - val_acc: 0.7642\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.4089 - acc: 0.8675 - val_loss: 0.6172 - val_acc: 0.8039\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.3389 - acc: 0.8932 - val_loss: 0.5245 - val_acc: 0.8276\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.2751 - acc: 0.9072 - val_loss: 0.4016 - val_acc: 0.8602\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.2526 - acc: 0.9169 - val_loss: 0.4213 - val_acc: 0.8497\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.2388 - acc: 0.9142 - val_loss: 0.3937 - val_acc: 0.8775\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1977 - acc: 0.9309 - val_loss: 0.3700 - val_acc: 0.8799\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 153s 21ms/step - loss: 0.1881 - acc: 0.9302 - val_loss: 0.2899 - val_acc: 0.8989\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 153s 21ms/step - loss: 0.1793 - acc: 0.9357 - val_loss: 0.3130 - val_acc: 0.9030\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.1629 - acc: 0.9389 - val_loss: 0.4082 - val_acc: 0.8717\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 153s 21ms/step - loss: 0.1590 - acc: 0.9449 - val_loss: 0.2927 - val_acc: 0.8982\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.1593 - acc: 0.9421 - val_loss: 0.2791 - val_acc: 0.9118\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1625 - acc: 0.9416 - val_loss: 0.2551 - val_acc: 0.9023\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1423 - acc: 0.9465 - val_loss: 0.3233 - val_acc: 0.8996\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.1400 - acc: 0.9471 - val_loss: 0.3931 - val_acc: 0.8853\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.1322 - acc: 0.9448 - val_loss: 0.3852 - val_acc: 0.8958\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1347 - acc: 0.9486 - val_loss: 0.3042 - val_acc: 0.8972\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 154s 21ms/step - loss: 0.1333 - acc: 0.9494 - val_loss: 0.3584 - val_acc: 0.9013\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 159s 22ms/step - loss: 0.1379 - acc: 0.9484 - val_loss: 0.3274 - val_acc: 0.8935\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 156s 21ms/step - loss: 0.1348 - acc: 0.9506 - val_loss: 0.4168 - val_acc: 0.8904\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 156s 21ms/step - loss: 0.1212 - acc: 0.9524 - val_loss: 0.4339 - val_acc: 0.8955\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1326 - acc: 0.9497 - val_loss: 0.2873 - val_acc: 0.9070\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1363 - acc: 0.9497 - val_loss: 0.3103 - val_acc: 0.9074\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 155s 21ms/step - loss: 0.1234 - acc: 0.9529 - val_loss: 0.2822 - val_acc: 0.9030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe95d5ef0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "ZnkgWOXVxkdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "05b9ca50-dbcb-4453-bcbc-89ed19a04447"
      },
      "cell_type": "code",
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.3))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 64)                18944     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 19,334\n",
            "Trainable params: 19,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7w_imZLmxpM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "542f75da-cd04-4383-a7e0-76e7961592b5"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 285s 39ms/step - loss: 1.2473 - acc: 0.4393 - val_loss: 1.1494 - val_acc: 0.4947\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 283s 38ms/step - loss: 0.8875 - acc: 0.6088 - val_loss: 0.8810 - val_acc: 0.6339\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 279s 38ms/step - loss: 0.6333 - acc: 0.7452 - val_loss: 0.6323 - val_acc: 0.7523\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 285s 39ms/step - loss: 0.5237 - acc: 0.8112 - val_loss: 1.4742 - val_acc: 0.6590\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 285s 39ms/step - loss: 0.3788 - acc: 0.8708 - val_loss: 0.4726 - val_acc: 0.8283\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 284s 39ms/step - loss: 0.2670 - acc: 0.9086 - val_loss: 0.3752 - val_acc: 0.8653\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 285s 39ms/step - loss: 0.2439 - acc: 0.9154 - val_loss: 0.5097 - val_acc: 0.8534\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.2177 - acc: 0.9227 - val_loss: 0.3397 - val_acc: 0.8870\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1724 - acc: 0.9393 - val_loss: 0.4729 - val_acc: 0.8728\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1582 - acc: 0.9414 - val_loss: 0.2719 - val_acc: 0.8890\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1699 - acc: 0.9389 - val_loss: 0.4493 - val_acc: 0.8921\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.2053 - acc: 0.9323 - val_loss: 0.3059 - val_acc: 0.8887\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 287s 39ms/step - loss: 0.1572 - acc: 0.9433 - val_loss: 0.2940 - val_acc: 0.9036\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1585 - acc: 0.9445 - val_loss: 0.2566 - val_acc: 0.9101\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1440 - acc: 0.9449 - val_loss: 0.2951 - val_acc: 0.9002\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 287s 39ms/step - loss: 0.1390 - acc: 0.9494 - val_loss: 0.6043 - val_acc: 0.8751\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 287s 39ms/step - loss: 0.1404 - acc: 0.9474 - val_loss: 0.3733 - val_acc: 0.8863\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1417 - acc: 0.9472 - val_loss: 0.4340 - val_acc: 0.9023\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 287s 39ms/step - loss: 0.1302 - acc: 0.9514 - val_loss: 0.5774 - val_acc: 0.8914\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1313 - acc: 0.9536 - val_loss: 0.4365 - val_acc: 0.8826\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 277s 38ms/step - loss: 0.1229 - acc: 0.9513 - val_loss: 0.3067 - val_acc: 0.9084\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1300 - acc: 0.9484 - val_loss: 0.3597 - val_acc: 0.9040\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1260 - acc: 0.9516 - val_loss: 0.3472 - val_acc: 0.9087\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 157s 21ms/step - loss: 0.1290 - acc: 0.9521 - val_loss: 0.3165 - val_acc: 0.9182\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1236 - acc: 0.9531 - val_loss: 0.3710 - val_acc: 0.9016\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 157s 21ms/step - loss: 0.1304 - acc: 0.9505 - val_loss: 0.4307 - val_acc: 0.9067\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1340 - acc: 0.9489 - val_loss: 0.4803 - val_acc: 0.9067\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1552 - acc: 0.9476 - val_loss: 0.3920 - val_acc: 0.9009\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 156s 21ms/step - loss: 0.1248 - acc: 0.9531 - val_loss: 0.5679 - val_acc: 0.8894\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 158s 21ms/step - loss: 0.1239 - acc: 0.9559 - val_loss: 0.3708 - val_acc: 0.9077\n",
            "<keras.callbacks.History at 0x7f5f2b979438>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XaZhgfvRx3fU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "32b6c965-eb33-44d0-8dd5-a0b73ebf9780"
      },
      "cell_type": "code",
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(100, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.3))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100)               44000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 44,606\n",
            "Trainable params: 44,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D3bFOZKGzdK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "b4026dc7-b54f-4fc6-a511-c827345be24c"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 168s 23ms/step - loss: 1.2575 - acc: 0.4504 - val_loss: 1.0486 - val_acc: 0.5341\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 160s 22ms/step - loss: 0.8674 - acc: 0.6202 - val_loss: 0.8185 - val_acc: 0.6559\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 160s 22ms/step - loss: 0.6527 - acc: 0.7387 - val_loss: 0.7363 - val_acc: 0.7394\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 186s 25ms/step - loss: 0.5149 - acc: 0.8150 - val_loss: 0.6321 - val_acc: 0.8052\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 281s 38ms/step - loss: 0.3619 - acc: 0.8758 - val_loss: 0.4775 - val_acc: 0.8449\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 284s 39ms/step - loss: 0.2702 - acc: 0.9101 - val_loss: 0.4027 - val_acc: 0.8731\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.2054 - acc: 0.9268 - val_loss: 0.3760 - val_acc: 0.8846\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 280s 38ms/step - loss: 0.1877 - acc: 0.9283 - val_loss: 0.3349 - val_acc: 0.8972\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 278s 38ms/step - loss: 0.1621 - acc: 0.9402 - val_loss: 0.2476 - val_acc: 0.9104\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 280s 38ms/step - loss: 0.1686 - acc: 0.9381 - val_loss: 0.3188 - val_acc: 0.8985\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 278s 38ms/step - loss: 0.1729 - acc: 0.9369 - val_loss: 0.2407 - val_acc: 0.9158\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 280s 38ms/step - loss: 0.1543 - acc: 0.9452 - val_loss: 0.3291 - val_acc: 0.9080\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 279s 38ms/step - loss: 0.1375 - acc: 0.9475 - val_loss: 0.4321 - val_acc: 0.8924\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 279s 38ms/step - loss: 0.1494 - acc: 0.9464 - val_loss: 0.3830 - val_acc: 0.9046\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 283s 39ms/step - loss: 0.1516 - acc: 0.9455 - val_loss: 0.3441 - val_acc: 0.9077\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1351 - acc: 0.9487 - val_loss: 0.2880 - val_acc: 0.9114\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1432 - acc: 0.9467 - val_loss: 0.3810 - val_acc: 0.9111\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1434 - acc: 0.9478 - val_loss: 0.2728 - val_acc: 0.9141\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 284s 39ms/step - loss: 0.1469 - acc: 0.9434 - val_loss: 0.3083 - val_acc: 0.9155\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 282s 38ms/step - loss: 0.1345 - acc: 0.9468 - val_loss: 0.3497 - val_acc: 0.9057\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 284s 39ms/step - loss: 0.1319 - acc: 0.9509 - val_loss: 0.3974 - val_acc: 0.9013\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 283s 39ms/step - loss: 0.1357 - acc: 0.9497 - val_loss: 0.4549 - val_acc: 0.8975\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 283s 38ms/step - loss: 0.1330 - acc: 0.9497 - val_loss: 0.3406 - val_acc: 0.9080\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 282s 38ms/step - loss: 0.1340 - acc: 0.9487 - val_loss: 0.4697 - val_acc: 0.9036\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 282s 38ms/step - loss: 0.1257 - acc: 0.9516 - val_loss: 0.2889 - val_acc: 0.9114\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 283s 39ms/step - loss: 0.1249 - acc: 0.9512 - val_loss: 0.3224 - val_acc: 0.9033\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1330 - acc: 0.9470 - val_loss: 0.2750 - val_acc: 0.9226\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1344 - acc: 0.9480 - val_loss: 0.3729 - val_acc: 0.8890\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 288s 39ms/step - loss: 0.1429 - acc: 0.9491 - val_loss: 0.3315 - val_acc: 0.9033\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 286s 39ms/step - loss: 0.1266 - acc: 0.9480 - val_loss: 0.3050 - val_acc: 0.9125\n",
            "<keras.callbacks.History at 0x7f55c03e98d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vJpkKEsDzsm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb3330a9-3731-4323-cfb7-23d57504bf0d"
      },
      "cell_type": "code",
      "source": [
        "max(model.history.history['val_acc'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9226331862911435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vUwBrN5nCpdz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3>Best Results are 0.9226331862911435 acc on validation data for single layer LSTM<h3>"
      ]
    },
    {
      "metadata": {
        "id": "5wqQE_37DBst",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>HyperParameter Tuning for 2 LSTM Layers<h1>"
      ]
    },
    {
      "metadata": {
        "id": "PseklpGs0b3F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(n_hidden,rate):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n_hidden,return_sequences=True, input_shape=(timesteps, input_dim)))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(LSTM(n_hidden))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Dense(n_classes, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZk_FleO3x0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6d87546e-a378-4c02-e2c2-74bbea4eead6"
      },
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0,epochs=30, batch_size=16)\n",
        "n_hidden = [32, 64, 100]\n",
        "rate = [0.3, 0.5,0.6]\n",
        "param_grid = dict(n_hidden=n_hidden, rate=rate)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train,Y_train,)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oebAaTxk4jqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "942ee03f-9417-4c94-bb8d-6dc9ed156db2"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.930596 using {'n_hidden': 64, 'rate': 0.3}\n",
            "0.898596 (0.038793) with: {'n_hidden': 32, 'rate': 0.3}\n",
            "0.903798 (0.051924) with: {'n_hidden': 32, 'rate': 0.5}\n",
            "0.88672 (0.007679) with: {'n_hidden': 32, 'rate': 0.6}\n",
            "0.930596 (0.020551) with: {'n_hidden': 64, 'rate': 0.3}\n",
            "0.929989 (0.111285) with: {'n_hidden': 64, 'rate': 0.5}\n",
            "0.917851 (0.015910) with: {'n_hidden': 64, 'rate': 0.6}\n",
            "0.924249 (0.021139) with: {'n_hidden': 100, 'rate': 0.3}\n",
            "0.920783 (0.014025) with: {'n_hidden': 100, 'rate': 0.5}\n",
            "0.903645 (0.048856) with: {'n_hidden': 100, 'rate': 0.6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WgQ7EFIg9s0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7337aa42-040f-411f-a1ca-7ceceb461207"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64,return_sequences=True, input_shape=(timesteps, input_dim)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128, 32)           5376      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 13,894\n",
            "Trainable params: 13,894\n",
            "Non-trainable params: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2fG0kNHi9_uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "b553d2be-09db-4c24-c7b8-a410feecf79a"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=16,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 576s 78ms/step - loss: 1.2719 - acc: 0.4706 - val_loss: 1.1341 - val_acc: 0.5969\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 573s 78ms/step - loss: 0.9618 - acc: 0.5943 - val_loss: 0.8548 - val_acc: 0.6457\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 563s 77ms/step - loss: 0.7380 - acc: 0.6533 - val_loss: 0.7752 - val_acc: 0.6349\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 565s 77ms/step - loss: 0.6620 - acc: 0.6937 - val_loss: 0.7196 - val_acc: 0.6780\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 566s 77ms/step - loss: 0.5637 - acc: 0.7665 - val_loss: 0.6397 - val_acc: 0.7794\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 580s 79ms/step - loss: 0.4617 - acc: 0.8243 - val_loss: 0.5165 - val_acc: 0.8521\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 583s 79ms/step - loss: 0.3495 - acc: 0.8908 - val_loss: 0.4711 - val_acc: 0.8633\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 576s 78ms/step - loss: 0.2612 - acc: 0.9202 - val_loss: 0.4767 - val_acc: 0.8483\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 575s 78ms/step - loss: 0.2182 - acc: 0.9310 - val_loss: 0.4830 - val_acc: 0.8938\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 575s 78ms/step - loss: 0.2146 - acc: 0.9338 - val_loss: 0.3966 - val_acc: 0.8914\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 575s 78ms/step - loss: 0.1794 - acc: 0.9388 - val_loss: 0.3376 - val_acc: 0.8928\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 583s 79ms/step - loss: 0.1915 - acc: 0.9415 - val_loss: 0.2878 - val_acc: 0.9021\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 557s 76ms/step - loss: 0.1685 - acc: 0.9448 - val_loss: 0.2417 - val_acc: 0.9055\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 329s 45ms/step - loss: 0.1613 - acc: 0.9433 - val_loss: 0.2461 - val_acc: 0.9002\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 324s 44ms/step - loss: 0.1554 - acc: 0.9445 - val_loss: 0.2303 - val_acc: 0.9283\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 324s 44ms/step - loss: 0.1537 - acc: 0.9470 - val_loss: 0.2208 - val_acc: 0.9153\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 321s 44ms/step - loss: 0.1454 - acc: 0.9487 - val_loss: 0.2458 - val_acc: 0.9092\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 321s 44ms/step - loss: 0.1448 - acc: 0.9456 - val_loss: 0.2823 - val_acc: 0.8982\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 321s 44ms/step - loss: 0.1427 - acc: 0.9459 - val_loss: 0.3775 - val_acc: 0.8965\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 318s 43ms/step - loss: 0.1414 - acc: 0.9465 - val_loss: 0.2847 - val_acc: 0.9119\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 318s 43ms/step - loss: 0.1464 - acc: 0.9461 - val_loss: 0.2621 - val_acc: 0.9306\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 318s 43ms/step - loss: 0.1371 - acc: 0.9495 - val_loss: 0.2603 - val_acc: 0.9080\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 318s 43ms/step - loss: 0.1422 - acc: 0.9504 - val_loss: 0.2855 - val_acc: 0.9070\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 318s 43ms/step - loss: 0.1340 - acc: 0.9497 - val_loss: 0.2919 - val_acc: 0.9026\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 319s 43ms/step - loss: 0.1489 - acc: 0.9502 - val_loss: 0.4191 - val_acc: 0.8877\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 319s 43ms/step - loss: 0.1696 - acc: 0.9465 - val_loss: 0.3314 - val_acc: 0.8992\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 320s 43ms/step - loss: 0.1438 - acc: 0.9510 - val_loss: 0.2308 - val_acc: 09199\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 322s 44ms/step - loss: 0.1391 - acc: 0.9489 - val_loss: 0.2566 - val_acc: 0.9036\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 321s 44ms/step - loss: 0.1328 - acc: 0.9504 - val_loss: 0.2650 - val_acc: 0.9258\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 324s 44ms/step - loss: 0.1271 - acc: 0.9535 - val_loss: 0.2609 - val_acc: 0.9101\n",
            "<keras.callbacks.History at 0x7fdeb6ee0c50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SBC27HCcBfQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8cc39e6-54cf-4331-bac2-5872a8b00ae8"
      },
      "cell_type": "code",
      "source": [
        "max(model.history.history['val_acc'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9306331862911436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EOnYp21mDZ2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h4>Best Results are 0.930633186291143 acc on validation data for 2 layer LSTM</h4>"
      ]
    },
    {
      "metadata": {
        "id": "sb93Ew1BEXDp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Report</h1>"
      ]
    },
    {
      "metadata": {
        "id": "othq0a2GG1hM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h4>Procedure</h4>\n",
        "The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    \n",
        " aggregating the signals by combination of sample/timestep.\n",
        " Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    \n",
        "  Hyperparameter Tuning For a single layer LSTM\n",
        "    \n",
        "   HyperParameter Tuning for 2 LSTM Layers"
      ]
    },
    {
      "metadata": {
        "id": "OXRDmWEoKU2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Results</h2>\n"
      ]
    },
    {
      "metadata": {
        "id": "beTD40gQKjL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03f40b7f-1a66-45ec-e71a-a26c841cfb8f"
      },
      "cell_type": "code",
      "source": [
        "print(\"NO OF LSTM Layers -----  1  ||Lstm Cells-----  100 || Droptut----- 0.3 || ValidationAccuracy-----  92.27%\")\n",
        "print(\"NO OF LSTM Layers ------ 2  ||Lstm Cells-----  64  || Droptut----- 0.3  ||ValidationAccuracy-----  93.06%\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO OF LSTM Layers -----  1  ||Lstm Cells-----  100 || Droptut----- 0.3 || ValidationAccuracy-----  92.27%\n",
            "NO OF LSTM Layers ------ 2  ||Lstm Cells-----  64  || Droptut----- 0.3  ||ValidationAccuracy-----  93.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oe8vkZrDNUZz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}